import pandas as pd
import numpy as np
import os
import sys
from pathlib import Path


# ========================
# å·¥å…·å‡½æ•°
# ========================

def get_user_choice(prompt, valid_choices, default=None):
    """é€šç”¨é€‰æ‹©å‡½æ•°"""
    while True:
        choice = input(prompt).strip()
        if not choice and default is not None:
            return default
        if choice in valid_choices:
            return choice
        print(f"è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ {'/'.join(valid_choices)}")


def exit_or_continue():
    """è¯¢é—®æ˜¯å¦ç»§ç»­ä½¿ç”¨å·¥å…·"""
    print("\n" + "=" * 50)
    choice = get_user_choice(
        "è¯·é€‰æ‹©: 1) è¿”å›ä¸»èœå•  2) é€€å‡ºç¨‹åºï¼ˆé»˜è®¤ 2ï¼‰: ",
        ['1', '2'], '2'
    )
    if choice == '1':
        return True
    else:
        print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
        sys.exit(0)


# ========================
# åˆå¹¶åŠŸèƒ½
# ========================

def merge_files():
    print("\n" + "=" * 40)
    print("=== CSV/XLSX æ–‡ä»¶åˆå¹¶å·¥å…· ===")
    print("=" * 40 + "\n")

    # 1. è¾“å…¥æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹
    input_type = get_user_choice(
        "è¯·é€‰æ‹©è¾“å…¥æ–¹å¼: 1) å¤šä¸ªæ–‡ä»¶è·¯å¾„ (ç©ºæ ¼åˆ†éš”)  2) æ•´ä¸ªæ–‡ä»¶å¤¹ï¼ˆé»˜è®¤ 2ï¼‰: ",
        ['1', '2'], '2'
    )

    file_paths = []
    if input_type == "1":
        paths_input = input("è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰: ").strip()
        if not paths_input:
            print("âŒ æœªè¾“å…¥æ–‡ä»¶è·¯å¾„ï¼")
            return
        file_paths = paths_input.split()
        for fp in file_paths:
            if not os.path.exists(fp):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {fp}")
                return
    else:
        folder_path = input("è¯·è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
        if not folder_path:
            folder_path = "."
        if not os.path.exists(folder_path) or not os.path.isdir(folder_path):
            print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨æˆ–æ— æ•ˆ: {folder_path}")
            return

        folder = Path(folder_path)
        file_paths = list(folder.glob("*.csv")) + list(folder.glob("*.xlsx")) + list(folder.glob("*.xls"))
        file_paths = [str(p) for p in file_paths]

        if not file_paths:
            print(f"âŒ åœ¨ {folder_path} ä¸­æœªæ‰¾åˆ° .csv æˆ– Excel æ–‡ä»¶ï¼")
            return

        print(f"âœ… æ‰¾åˆ° {len(file_paths)} ä¸ªæ–‡ä»¶:")
        for i, fp in enumerate(file_paths):
            print(f"  {i + 1}. {fp}")

    # 2. æ’åº
    sort_choice = get_user_choice("æ˜¯å¦æŒ‰æ–‡ä»¶åæ’åºï¼Ÿ(y/n, é»˜è®¤ y): ", ['y', 'n'], 'y')
    if sort_choice == 'y':
        file_paths.sort()

    # 3. è¯»å–æ–‡ä»¶
    dataframes = []
    all_columns = set()
    common_columns = None

    print("\næ­£åœ¨è¯»å–æ–‡ä»¶...")
    for file in file_paths:
        ext = os.path.splitext(file)[1].lower()
        try:
            if ext == '.csv':
                total_lines, encoding = count_csv_lines(file)
                if total_lines is None:
                    print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶ï¼ˆç¼–ç ä¸æ”¯æŒï¼‰: {file}")
                    continue
                print(f"ğŸ” ä½¿ç”¨ç¼–ç  {encoding} è¯»å– {os.path.basename(file)}")
                df = pd.read_csv(file, encoding=encoding)
                data_rows = len(df)
                print(f"âœ“ {os.path.basename(file)}: "
                      f"æ€»è¡Œæ•°ï¼ˆå«è¡¨å¤´ï¼‰= {total_lines} è¡Œ, "
                      f"å®é™…æ•°æ®è¡Œ = {data_rows} è¡Œ, "
                      f"åˆ—æ•° = {len(df.columns)}")
            elif ext in ['.xlsx', '.xls']:
                df = pd.read_excel(file)
                data_rows = len(df)
                total_lines = data_rows + 1
                print(f"âœ“ {os.path.basename(file)}: "
                      f"æ€»è¡Œæ•°ï¼ˆå«è¡¨å¤´ï¼‰â‰ˆ {total_lines} è¡Œ (ä¼°ç®—), "
                      f"å®é™…æ•°æ®è¡Œ = {data_rows} è¡Œ, "
                      f"åˆ—æ•° = {len(df.columns)}")
            else:
                print(f"è·³è¿‡ä¸æ”¯æŒçš„æ ¼å¼: {file}")
                continue

            dataframes.append((file, df))
            all_columns.update(df.columns)
            if common_columns is None:
                common_columns = set(df.columns)
            else:
                common_columns &= set(df.columns)
        except Exception as e:
            print(f"âŒ è¯»å–å¤±è´¥ {file}: {type(e).__name__}: {e}")

    if not dataframes:
        print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ–‡ä»¶ï¼")
        return

    print(f"\nğŸ“‹ æ‰€æœ‰æ–‡ä»¶ä¸­å‡ºç°è¿‡çš„åˆ—: {sorted(all_columns)}")
    print(f"ğŸ”¹ æ‰€æœ‰æ–‡ä»¶å…±æœ‰çš„åˆ—: {sorted(common_columns)}")

    # 4. é€‰æ‹©åˆ—
    print(f"\nå½“å‰æ‰€æœ‰æ•°æ®å…±åŒ…å« {len(all_columns)} ä¸ªä¸åŒçš„åˆ—ã€‚")
    col_choice = get_user_choice("æ˜¯å¦åªä¿ç•™æ‰€æœ‰æ–‡ä»¶å…±æœ‰çš„åˆ—ï¼Ÿ(y/n, é»˜è®¤ n): ", ['y', 'n'], 'n')

    if col_choice == 'y' and common_columns:
        selected_columns = sorted(common_columns)
        print(f"âœ… å·²é€‰æ‹©å…±æœ‰çš„åˆ—: {selected_columns}")
    else:
        selected_columns_input = input("è¯·è¾“å…¥è¦ä¿ç•™çš„åˆ—åï¼ˆè‹±æ–‡é€—å·åˆ†éš”ï¼Œç•™ç©ºè¡¨ç¤ºå…¨éƒ¨åˆ—ï¼‰: ").strip()
        if selected_columns_input:
            selected_columns = [col.strip() for col in selected_columns_input.split(',')]
            existing_cols = [col for col in selected_columns if col in all_columns]
            if not existing_cols:
                print("âŒ è­¦å‘Šï¼šä½ æŒ‡å®šçš„åˆ—åœ¨ä»»ä½•æ–‡ä»¶ä¸­éƒ½ä¸å­˜åœ¨ï¼")
                return
            selected_columns = existing_cols
        else:
            selected_columns = sorted(all_columns)

    # 5. é‡å‘½ååˆ—
    print(f"\nğŸ“¤ å½“å‰è¾“å‡ºåˆ—: {selected_columns}")
    rename_choice = get_user_choice("æ˜¯å¦è¦é‡å‘½åè¾“å‡ºåˆ—ï¼Ÿ(y/n, é»˜è®¤ n): ", ['y', 'n'], 'n')
    column_mapping = {}

    if rename_choice == 'y':
        print("è¯·ä¸ºæ¯ä¸€åˆ—è¾“å…¥æ–°çš„åˆ—åï¼ˆç•™ç©ºåˆ™ä¿æŒåŸåï¼‰:")
        for col in selected_columns:
            new_name = input(f"å°† '{col}' é‡å‘½åä¸ºï¼ˆç•™ç©ºä¸å˜ï¼‰: ").strip()
            column_mapping[col] = new_name if new_name else col
    else:
        column_mapping = {col: col for col in selected_columns}

    final_columns = [column_mapping[col] for col in selected_columns]

    # 6. ç©ºå€¼å¤„ç†
    print(f"\nğŸ§¹ æ˜¯å¦åˆ é™¤å…¨ä¸ºç©ºï¼ˆæˆ–å…¨ç©ºç™½ï¼‰çš„è¡Œï¼Ÿ")
    print("   ï¼ˆç©ºå­—ç¬¦ä¸²ã€ç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ç­‰å°†è¢«è§†ä¸ºç¼ºå¤±å€¼ï¼‰")
    clean_empty = get_user_choice("æ˜¯å¦åˆ é™¤ï¼Ÿ(y/n, é»˜è®¤ y): ", ['y', 'n'], 'y') == 'y'

    # 7. åˆå¹¶
    merged_rows = 0
    combined_df = pd.DataFrame(columns=final_columns)

    print("\nğŸ”„ æ­£åœ¨åˆå¹¶æ•°æ®...")

    for i, (file, df) in enumerate(dataframes):
        temp_df = df.reindex(columns=selected_columns)
        temp_df.columns = final_columns

        if clean_empty:
            temp_df.replace(r'^\s*$', np.nan, regex=True, inplace=True)
            temp_df.dropna(how='all', inplace=True)

        combined_df = pd.concat([combined_df, temp_df], ignore_index=True)
        merged_rows += len(temp_df)
        print(f"  âœ”ï¸ å·²åˆå¹¶: {os.path.basename(file)} -> {len(temp_df)} è¡Œ")

    print(f"âœ… åˆå¹¶å®Œæˆï¼å…±åˆå¹¶ {merged_rows} è¡Œæ•°æ®ã€‚")

    expected_data_rows = sum([len(df) for _, df in dataframes])
    if merged_rows != expected_data_rows:
        print(f"âš ï¸  æ³¨æ„ï¼šå®é™…åˆå¹¶ {merged_rows} è¡Œï¼Œé¢„æœŸ {expected_data_rows} è¡Œã€‚")
        print(f"    å¯èƒ½åŸå› ï¼šæ£€æµ‹åˆ° {expected_data_rows - merged_rows} è¡Œå…¨ç©ºï¼ˆæˆ–å…¨ç©ºç™½ï¼‰ï¼Œå·²è¢«åˆ é™¤ã€‚")
    else:
        print(f"âœ… æ•°æ®è¡Œæ•°åŒ¹é…ï¼Œåˆå¹¶å®Œæ•´ã€‚")

    # 8. è¾“å‡º
    output_format = get_user_choice("è¯·é€‰æ‹©è¾“å‡ºæ ¼å¼: 1) CSV  2) XLSXï¼ˆé»˜è®¤ 1ï¼‰: ", ['1', '2'], '1')
    output_ext = ".xlsx" if output_format == "2" else ".csv"

    output_file = input("è¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå«æ–‡ä»¶åï¼‰: ").strip()
    if not output_file:
        base_name = "merged_output"
        output_file = f"{base_name}{output_ext}"
    elif not output_file.lower().endswith(('.csv', '.xlsx')):
        output_file += output_ext

    output_dir = os.path.dirname(output_file)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # 9. ä¿å­˜
    try:
        if output_ext == ".csv":
            combined_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            print(f"ğŸ‰ æˆåŠŸä¿å­˜ä¸º CSV: {output_file}")
        else:
            combined_df.to_excel(output_file, index=False, sheet_name="MergedData")
            print(f"ğŸ‰ æˆåŠŸä¿å­˜ä¸º Excel: {output_file}")
        print(f"ğŸ“Š è¾“å‡ºæ–‡ä»¶æ€»è¡Œæ•°ï¼ˆå«è¡¨å¤´ï¼‰: {len(combined_df) + 1} è¡Œï¼ˆæ•°æ®è¡Œæ•°: {len(combined_df)}ï¼‰")
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {type(e).__name__}: {e}")


def count_csv_lines(file_path):
    encodings = ['utf-8', 'gbk', 'utf-8-sig', 'cp1252', 'latin1']
    for encoding in encodings:
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                return sum(1 for _ in f), encoding
        except:
            continue
    return None, None


# ========================
# åˆ†å‰²åŠŸèƒ½
# ========================

def get_file_path(prompt):
    """è·å–æœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„"""
    while True:
        file_path = input(prompt).strip().replace("'", "").replace('"', '')
        if not os.path.exists(file_path):
            print("é”™è¯¯ï¼šæ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
        elif not (file_path.endswith('.xlsx') or file_path.endswith('.csv')):
            print("é”™è¯¯ï¼šæ–‡ä»¶æ ¼å¼ä¸æ”¯æŒï¼Œè¯·ç¡®ä¿æ˜¯ .xlsx æˆ– .csv æ–‡ä»¶ã€‚")
        else:
            return file_path


def get_output_dir(prompt):
    """è·å–æœ‰æ•ˆçš„è¾“å‡ºç›®å½•"""
    while True:
        output_dir = input(prompt).strip().replace("'", "").replace('"', '')
        if not output_dir:
            output_dir = "."
        if not os.path.isdir(output_dir):
            try:
                os.makedirs(output_dir, exist_ok=True)
                print(f"ç›®å½•ä¸å­˜åœ¨ï¼Œå·²ä¸ºæ‚¨åˆ›å»ºï¼š{output_dir}")
                return output_dir
            except Exception as e:
                print(f"æ— æ³•åˆ›å»ºç›®å½•ï¼š{e}ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
        else:
            return output_dir


def read_and_process_file(file_path):
    """è¯»å–æ–‡ä»¶å¹¶å¤„ç†åˆ—å"""
    try:
        if file_path.endswith('.xlsx'):
            df = pd.read_excel(file_path)
        else:
            df = pd.read_csv(file_path, dtype=str, encoding='utf-8', on_bad_lines='skip')

        # å°†æ‰€æœ‰åˆ—å¼ºåˆ¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œä»¥ä¿ç•™å¤§æ•°å­—çš„ç²¾åº¦
        df = df.astype(str)

        columns = df.columns.tolist()
        print("\nå½“å‰æ–‡ä»¶çš„åˆ—åå¦‚ä¸‹ï¼š")
        print("['" + "', '".join(columns) + "']")

        while True:
            selection_input = input("\nè¯·è¾“å…¥æ‚¨æƒ³ä¿ç•™çš„åˆ—åï¼ˆä»¥é€—å·åˆ†éš”ï¼Œç•™ç©ºé»˜è®¤é€‰æ‹©æ‰€æœ‰ï¼‰ï¼š").strip()
            if not selection_input:
                selected_columns = columns
            else:
                selected_columns = [col.strip() for col in selection_input.split(',')]
                invalid_cols = [col for col in selected_columns if col not in columns]
                if invalid_cols:
                    print(f"é”™è¯¯ï¼šä»¥ä¸‹åˆ—åä¸å­˜åœ¨ï¼š{invalid_cols}ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                    continue
            break

        rename_choice = input("æ˜¯å¦éœ€è¦é‡å‘½åè¿™äº›åˆ—ï¼Ÿ(y/n)ï¼Œç•™ç©ºé»˜è®¤ä¸é‡å‘½å: ").strip().lower()
        if rename_choice == 'y':
            new_names = []
            for col in selected_columns:
                new_name = input(f"è¯·è¾“å…¥ '{col}' çš„æ–°åç§°ï¼š").strip()
                new_names.append(new_name if new_name else col)
            rename_map = dict(zip(selected_columns, new_names))
            df = df.rename(columns=rename_map)
            print("\nåˆ—åå·²æ›´æ–°ä¸ºï¼š['" + "', '".join(new_names) + "']")
            selected_columns = new_names
        else:
            print("\nå·²é€‰æ‹©ä¸é‡å‘½ååˆ—ã€‚")

        return df[selected_columns]

    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
        return None


def slice_by_count(df):
    """æŒ‰è¡Œæ•°æˆªå–"""
    while True:
        try:
            start_row = int(input("\nè¯·è¾“å…¥å¼€å§‹æˆªå–çš„è¡Œæ•°ï¼ˆä»1å¼€å§‹è®¡æ•°ï¼‰ï¼š"))
            if start_row <= 0:
                print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ä¸€ä¸ªå¤§äº0çš„æ•´æ•°ã€‚")
                continue
            start_row -= 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
            if start_row >= len(df):
                print(f"å¼€å§‹è¡Œè¶…å‡ºæ–‡ä»¶æ€»è¡Œæ•°ï¼ˆ{len(df)}ï¼‰ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                continue
            break
        except ValueError:
            print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ä¸€ä¸ªéè´Ÿæ•´æ•°ã€‚")

    while True:
        try:
            row_count = int(input("è¯·è¾“å…¥æ¯æ¬¡æˆªå–çš„è¡Œæ•°ï¼š"))
            if row_count <= 0:
                print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ä¸€ä¸ªå¤§äº0çš„æ•´æ•°ã€‚")
                continue
            break
        except ValueError:
            print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ä¸€ä¸ªå¤§äº0çš„æ•´æ•°ã€‚")

    while True:
        try:
            slice_times = int(input("è¯·è¾“å…¥éœ€è¦è¿™æ ·æˆªå–å‡ æ¬¡ï¼š"))
            if slice_times <= 0:
                print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ä¸€ä¸ªå¤§äº0çš„æ•´æ•°ã€‚")
                continue
            break
        except ValueError:
            print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ä¸€ä¸ªå¤§äº0çš„æ•´æ•°ã€‚")

    sliced_dfs = []
    for i in range(slice_times):
        start = start_row + i * row_count
        end = start + row_count
        if start >= len(df):
            break
        sliced_dfs.append(df.iloc[start:end])
    return sliced_dfs


def slice_by_end_row(df):
    """æŒ‰è¡ŒèŒƒå›´æˆªå–"""
    while True:
        try:
            start_row = int(input("\nè¯·è¾“å…¥å¼€å§‹æˆªå–çš„è¡Œæ•°ï¼ˆä»1å¼€å§‹è®¡æ•°ï¼‰ï¼š"))
            if start_row <= 0:
                print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ä¸€ä¸ªå¤§äº0çš„æ•´æ•°ã€‚")
                continue
            if start_row > len(df):
                print(f"å¼€å§‹è¡Œè¶…å‡ºæ–‡ä»¶æ€»è¡Œæ•°ï¼ˆ{len(df)}ï¼‰ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                continue
            break
        except ValueError:
            print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ä¸€ä¸ªéè´Ÿæ•´æ•°ã€‚")

    while True:
        try:
            end_row = int(input("è¯·è¾“å…¥æˆªå–åˆ°ç¬¬å‡ è¡Œï¼ˆä¸åŒ…å«æ­¤è¡Œï¼Œä»1å¼€å§‹è®¡æ•°ï¼‰ï¼š"))
            if end_row <= start_row:
                print("ç»“æŸè¡Œå¿…é¡»å¤§äºå¼€å§‹è¡Œã€‚")
                continue
            if end_row > len(df) + 1:
                print(f"ç»“æŸè¡Œè¶…å‡ºæ–‡ä»¶æ€»è¡Œæ•°ï¼ˆ{len(df)}ï¼‰ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")
                continue
            break
        except ValueError:
            print("è¾“å…¥æ— æ•ˆï¼Œè¯·é€‰æ‹© 'csv' æˆ– 'xlsx'ã€‚")

    start_row -= 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
    end_row -= 1  # è½¬æ¢ä¸º0-basedç´¢å¼•

    while True:
        try:
            num_slices = int(input("è¯·è¾“å…¥éœ€è¦æˆªå–å‡ æ®µï¼š"))
            if num_slices <= 0:
                print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ä¸€ä¸ªå¤§äº0çš„æ•´æ•°ã€‚")
                continue
            break
        except ValueError:
            print("è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ä¸€ä¸ªå¤§äº0çš„æ•´æ•°ã€‚")

    total_rows = end_row - start_row
    slice_length = total_rows // num_slices

    sliced_dfs = []
    for i in range(num_slices):
        start = start_row + i * slice_length
        end = start + slice_length
        sliced_dfs.append(df.iloc[start:end])
    return sliced_dfs


def split_excel_or_csv():
    print("\n" + "=" * 40)
    print("=== CSV/XLSX æ–‡ä»¶åˆ†å‰²å·¥å…· ===")
    print("=" * 40 + "\n")

    file_path = get_file_path("è¯·è¾“å…¥æ‚¨è¦æˆªå–çš„ Excel æˆ– CSV æ–‡ä»¶è·¯å¾„ï¼š")

    processed_df = read_and_process_file(file_path)
    if processed_df is None:
        return

    while True:
        slice_method = input(
            "\nè¯·é€‰æ‹©æˆªå–æ–¹å¼ï¼š\n1. æŒ‡å®šæˆªå–å¤šå°‘è¡Œï¼Œå¹¶é‡å¤æˆªå–ç›¸åŒè¡Œæ•°å‡ æ¬¡\n2. æŒ‡å®šæˆªå–åˆ°ç¬¬å‡ è¡Œï¼Œå¹¶å°†æˆªå–åˆ°çš„éƒ¨åˆ†åˆ’ä¸ºå‡ æ®µ\nè¯·é€‰æ‹© (1/2): ").strip()
        if slice_method == '1':
            sliced_dataframes = slice_by_count(processed_df)
            break
        elif slice_method == '2':
            sliced_dataframes = slice_by_end_row(processed_df)
            break
        else:
            print("æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥ã€‚")

    if not sliced_dataframes:
        print("æœªç”Ÿæˆä»»ä½•æˆªå–æ•°æ®ï¼Œç¨‹åºç»“æŸã€‚")
        return

    output_dir = get_output_dir("\nè¯·è¾“å…¥ä¿å­˜æˆªå–æ–‡ä»¶çš„ç›®å½•åœ°å€ï¼ˆç•™ç©ºåˆ™ä¸ºå½“å‰ç›®å½•ï¼‰ï¼š")
    if not output_dir:
        output_dir = "."

    output_filename_base = input("\nè¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶çš„åç§°å‰ç¼€ï¼ˆä¾‹å¦‚ï¼šmy_dataï¼Œç•™ç©ºåˆ™ä¸º 'output'ï¼‰ï¼š").strip()
    if not output_filename_base:
        output_filename_base = "output"

    while True:
        output_format = input("è¯·é€‰æ‹©è¾“å‡ºæ–‡ä»¶æ ¼å¼ (csv/xlsx): ").strip().lower()
        if output_format in ['csv', 'xlsx']:
            break
        else:
            print("æ— æ•ˆçš„æ ¼å¼ï¼Œè¯·é€‰æ‹© 'csv' æˆ– 'xlsx'ã€‚")

    for i, df_slice in enumerate(sliced_dataframes):
        df = df_slice.copy()

        output_filename = f"{output_filename_base}_part_{i + 1}.{output_format}"
        output_path = os.path.join(output_dir, output_filename)

        try:
            if output_format == 'xlsx':
                df.to_excel(output_path, index=False)
            else:
                # ä½¿ç”¨ utf-8-sig ç¼–ç 
                df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"æ–‡ä»¶å·²ä¿å­˜è‡³ï¼š{output_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥ {output_path}: {e}")

    print("\næ‰€æœ‰æˆªå–æ“ä½œå·²å®Œæˆï¼")


# ========================
# æŸ¥é‡åŠŸèƒ½
# ========================

def read_file(file_path, sheet=None):
    ext = file_path.suffix.lower()
    try:
        if ext in ['.xlsx', '.xls']:
            excel_file = pd.ExcelFile(file_path)
            if sheet is None:
                sheet = excel_file.sheet_names[0]
            df = pd.read_excel(file_path, sheet_name=sheet, dtype=str)
            return df, excel_file.sheet_names
        elif ext == '.csv':
            df = pd.read_csv(file_path, dtype=str, low_memory=False)
            return df, ["CSV"]
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")
    except Exception as e:
        raise RuntimeError(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")


def get_column_data(df, column):
    """
    æ”¯æŒä¸‰ç§è¾“å…¥æ–¹å¼ï¼š
    1. åˆ—åï¼ˆå¦‚ 'email'ï¼‰
    2. åˆ—å­—æ¯ï¼ˆå¦‚ 'B'ï¼‰
    3. åˆ—åºå·ï¼ˆå¦‚ '2' æˆ– 2ï¼‰
    è¿”å›è¯¥åˆ—æ‰€æœ‰éç©ºå€¼çš„é›†åˆï¼ˆå­—ç¬¦ä¸²ï¼‰
    """
    col_key = str(column).strip()

    # æƒ…å†µ1ï¼šå…ˆå°è¯•å½“ä½œåˆ—åæŸ¥æ‰¾
    if col_key in df.columns:
        return set(df[col_key].dropna().astype(str))

    # æƒ…å†µ2ï¼šå¦‚æœä¸æ˜¯åˆ—åï¼Œå†å°è¯•å½“ä½œåˆ—åºå·ï¼ˆçº¯æ•°å­—ï¼‰
    if col_key.isdigit():
        idx = int(col_key) - 1  # è½¬ä¸ºä»0å¼€å§‹
        if 0 <= idx < len(df.columns):
            return set(df.iloc[:, idx].dropna().astype(str))
        else:
            raise ValueError(f"åˆ—åºå· {int(col_key)} è¶…å‡ºèŒƒå›´ [1, {len(df.columns)}]")

    # æƒ…å†µ3ï¼šå†å°è¯•å½“ä½œåˆ—å­—æ¯ï¼ˆå¦‚ 'B'ï¼‰
    if len(col_key) == 1 and col_key.isalpha():
        idx = ord(col_key.upper()) - ord('A')
        if 0 <= idx < len(df.columns):
            return set(df.iloc[:, idx].dropna().astype(str))
        else:
            raise ValueError(f"åˆ—å­—æ¯ '{col_key}' è¶…å‡ºèŒƒå›´ [A-{chr(ord('A') + len(df.columns) - 1)}]")

    # éƒ½ä¸åŒ¹é…ï¼ŒæŠ¥é”™
    available_cols = list(df.columns)
    raise ValueError(f"æ— æ³•æ‰¾åˆ°åˆ— '{col_key}'ã€‚å¯ç”¨åˆ—åï¼š{available_cols}")


def select_sheet(sheet_names):
    # æ¯ä¸ª Sheet åç”¨ ' ' åŒ…è£¹ï¼Œé€—å·åˆ†éš”ï¼Œä¸åŠ  [ ]
    sheets_quoted = ", ".join(f"'{name}'" for name in sheet_names)
    print(f"å¯ç”¨çš„ Sheet åˆ—è¡¨: {sheets_quoted}")

    default_sheet = sheet_names[0]
    print(f"æç¤ºï¼šç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤ [{default_sheet}]")

    choice = input("è¯·é€‰æ‹© Sheetï¼ˆè¾“å…¥åºå·æˆ–åç§°ï¼‰: ").strip()
    if not choice:
        return default_sheet

    if choice.isdigit():
        idx = int(choice) - 1
        if 0 <= idx < len(sheet_names):
            return sheet_names[idx]
        else:
            print(f"åºå·è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤ [{default_sheet}]")
            return default_sheet
    else:
        if choice in sheet_names:
            return choice
        else:
            print(f"æœªæ‰¾åˆ° Sheet '{choice}'ï¼Œä½¿ç”¨é»˜è®¤ [{default_sheet}]")
            return default_sheet


def deduplicate_files():
    print("\n" + "=" * 40)
    print("=== CSV/XLSX æ–‡ä»¶æŸ¥é‡åˆ é™¤å·¥å…· ===")
    print("=" * 40 + "\n")

    # 1. è¾“å…¥ä¸»æ–‡ä»¶è·¯å¾„
    main_path = input("è¯·è¾“å…¥ä¸»æ–‡ä»¶è·¯å¾„ï¼ˆè¢«æŸ¥é‡çš„æ–‡ä»¶ï¼‰: ").strip().strip('"\'')
    main_file = Path(main_path)
    if not main_file.exists():
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {main_file}")
        return

    # è¯»å–ä¸»æ–‡ä»¶
    try:
        main_df, main_sheets = read_file(main_file)
        print(f"æˆåŠŸè¯»å–ä¸»æ–‡ä»¶ï¼Œå…± {len(main_sheets)} ä¸ª Sheetã€‚")
        main_sheet = select_sheet(main_sheets)

        # é‡æ–°è¯»å–ç”¨æˆ·é€‰æ‹©çš„ sheetï¼ˆä¿æŒ dtype=strï¼‰
        if main_file.suffix.lower() in ['.xlsx', '.xls']:
            main_df = pd.read_excel(main_file, sheet_name=main_sheet, dtype=str)
        # CSV å·²è¯»å–ï¼Œæ— éœ€å†å¤„ç†

    except Exception as e:
        print(f"è¯»å–ä¸»æ–‡ä»¶å¤±è´¥: {e}")
        return

    # æ˜¾ç¤ºåˆ—åï¼ˆæ¯ä¸ªåˆ—ååŠ  ' 'ï¼Œé€—å·åˆ†éš”ï¼Œä¸åŠ  [ ]ï¼‰
    columns_quoted = ", ".join(f"'{col}'" for col in main_df.columns)
    print(f"\nä¸»æ–‡ä»¶ '{main_sheet}' çš„åŸå§‹åˆ—å: {columns_quoted}")
    main_column = input("è¯·è¾“å…¥ä¸»æ–‡ä»¶ç”¨äºæ¯”è¾ƒçš„åˆ—å: ").strip()
    if not main_column:
        print("åˆ—åä¸èƒ½ä¸ºç©ºï¼")
        return

    # 2. è¾“å…¥å¯¹æ¯”æ–‡ä»¶
    print("\nè¯·è¾“å…¥å¯¹æ¯”æ–‡ä»¶è·¯å¾„ï¼ˆå¤šä¸ªç”¨åˆ†å· ; åˆ†éš”ï¼Œæˆ–ä¸€è¡Œä¸€ä¸ªï¼Œç©ºè¡Œç»“æŸï¼‰:")
    ref_input = input().strip()
    ref_files = []
    if ';' in ref_input:
        ref_files = [Path(p.strip().strip('"\'')) for p in ref_input.split(';') if p.strip()]
    else:
        if ref_input:
            ref_files.append(Path(ref_input.strip('"\'')))
        while True:
            line = input().strip()
            if not line:
                break
            ref_files.append(Path(line.strip('"\'')))

    valid_ref_files = [f for f in ref_files if f.exists()]
    if not valid_ref_files:
        print("æ²¡æœ‰æœ‰æ•ˆçš„å¯¹æ¯”æ–‡ä»¶ï¼")
        return

    for f in ref_files:
        if not f.exists():
            print(f"è·³è¿‡ä¸å­˜åœ¨çš„æ–‡ä»¶: {f}")

    # 3. é…ç½®å¯¹æ¯”æ–‡ä»¶
    ref_configs = []
    print("\né…ç½®æ¯ä¸ªå¯¹æ¯”æ–‡ä»¶çš„ Sheet å’Œæ¯”è¾ƒåˆ—:")
    for file in valid_ref_files:
        print(f"\n--- {file.name} ---")
        try:
            _, sheets = read_file(file)
            sheet = select_sheet(sheets)

            # è¯»å–æŒ‡å®š sheet
            if file.suffix.lower() in ['.xlsx', '.xls']:
                df_temp = pd.read_excel(file, sheet_name=sheet, dtype=str)
            else:
                df_temp = pd.read_csv(file, dtype=str, low_memory=False)

            # æ˜¾ç¤ºåˆ—åï¼ˆåŠ å¼•å·ï¼Œå»æ‹¬å·ï¼‰
            columns_quoted = ", ".join(f"'{col}'" for col in df_temp.columns)
            print(f"åˆ—å: {columns_quoted}")

            col = input("æ¯”è¾ƒåˆ—å: ").strip()
            if not col:
                print("åˆ—ä¸èƒ½ä¸ºç©ºï¼Œè·³è¿‡æ­¤æ–‡ä»¶ã€‚")
                continue

            ref_configs.append({
                'file': file,
                'sheet': sheet,
                'column': col,
                'df': df_temp
            })
        except Exception as e:
            print(f"è¯»å–å¤±è´¥: {e}")

    if not ref_configs:
        print("æ²¡æœ‰é…ç½®ä»»ä½•æœ‰æ•ˆçš„å¯¹æ¯”æ–‡ä»¶ï¼")
        return

    # 4. æŸ¥é‡å¤„ç†
    print("\nå¼€å§‹æŸ¥é‡å¤„ç†...")
    try:
        main_values_set = get_column_data(main_df, main_column)
        print(f"ä¸»æ–‡ä»¶ '{main_column}' åˆ—å…± {len(main_values_set)} ä¸ªå”¯ä¸€å€¼ï¼ˆä»…ç”¨äºæ£€æŸ¥ï¼‰ã€‚")

        all_ref_values = set()
        for config in ref_configs:
            df = config['df']
            col = config['column']
            print(f"å¤„ç†: {config['file'].name} [{config['sheet']}] åˆ— '{col}'")
            values = get_column_data(df, col)
            all_ref_values.update(values)
            print(f"æ·»åŠ  {len(values)} ä¸ªå€¼ï¼Œç´¯è®¡ {len(all_ref_values)} ä¸ªã€‚")

        print(f"æ€»å…± {len(all_ref_values)} ä¸ªç”¨äºæŸ¥é‡çš„å€¼ã€‚")

        def is_duplicate(row):
            key = row.get(main_column)
            if pd.isna(key) or key is None:
                return False
            return str(key).strip() in all_ref_values

        mask = main_df.apply(is_duplicate, axis=1)
        removed_count = mask.sum()
        filtered_df = main_df[~mask]

        print(f"æŸ¥é‡å®Œæˆï¼åˆ é™¤ {removed_count} è¡Œï¼Œå‰©ä½™ {len(filtered_df)} è¡Œã€‚")

        # 5. ä¿å­˜ç»“æœ
        output_path = input("\nè¯·è¾“å…¥ä¿å­˜è·¯å¾„ï¼ˆå¦‚ result.xlsxï¼‰: ").strip().strip('"\'')
        if not output_path:
            print("æœªæŒ‡å®šä¿å­˜è·¯å¾„ï¼")
            return

        output_file = Path(output_path)
        try:
            if output_file.suffix.lower() == '.csv':
                filtered_df.to_csv(output_file, index=False, encoding='utf-8-sig')
            else:
                filtered_df.to_excel(output_file, index=False, engine='openpyxl')
            print(f"æˆåŠŸä¿å­˜è‡³:\n   {output_file.resolve()}")
        except Exception as e:
            print(f"ä¿å­˜å¤±è´¥: {e}")

    except Exception as e:
        print(f"å¤„ç†å¤±è´¥: {e}")
        return


# ========================
# æ¸…ç†ç©ºè¡ŒåŠŸèƒ½
# ========================

def clean_spreadsheet_main():
    print("\n" + "=" * 40)
    print("=== è¡¨æ ¼æ–‡ä»¶è¡Œè¿‡æ»¤å·¥å…·ï¼ˆåˆ é™¤æŒ‡å®šåˆ—ä¸ºç©ºçš„è¡Œï¼‰ ===")
    print("=" * 40 + "\n")

    # 1. è¾“å…¥æ–‡ä»¶è·¯å¾„
    input_path = input("ğŸ“Œ è¯·è¾“å…¥æˆ–æ‹–å…¥ CSV/XLSX æ–‡ä»¶è·¯å¾„: ").strip().strip('"\'')
    if not input_path or not os.path.exists(input_path):
        print("âŒ æ–‡ä»¶è·¯å¾„æ— æ•ˆæˆ–ä¸å­˜åœ¨ï¼")
        return

    # 2. è‡ªåŠ¨è¯»å–åˆ—å
    ext = os.path.splitext(input_path)[1].lower()
    try:
        if ext == '.csv':
            df = pd.read_csv(input_path, nrows=0)  # åªè¯»æ ‡é¢˜
        elif ext in ['.xlsx', '.xls']:
            df = pd.read_excel(input_path, nrows=0)
        else:
            print("âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼ä»…æ”¯æŒ .csvã€.xlsxã€.xls")
            return
        columns = df.columns.tolist()
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶åˆ—å: {e}")
        return

    if not columns:
        print("âš ï¸  æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åˆ—ã€‚")
        return

    # æ˜¾ç¤ºåˆ—å
    print("\nğŸ“‹ æ–‡ä»¶ä¸­çš„åˆ—åå¦‚ä¸‹ï¼š")
    for i, col in enumerate(columns, 1):
        print(f"   {i:2d}. {col}")

    # 3. è®©ç”¨æˆ·é€‰æ‹©åˆ—ï¼ˆæ”¯æŒè¾“å…¥åˆ—åæˆ–åºå·ï¼‰
    print("\nğŸ’¡ è¯·è¾“å…¥è¦æ£€æŸ¥ç©ºç™½çš„åˆ—ï¼š")
    print("   â€¢ å¯è¾“å…¥åˆ—åï¼Œå¤šä¸ªç”¨è‹±æ–‡é€—å·åˆ†éš”ï¼Œå¦‚ï¼šEmail,Name")
    print("   â€¢ æˆ–è¾“å…¥åˆ—åºå·ï¼Œå¦‚ï¼š1,3,5")
    choice = input("\nğŸ‘‰ è¯·è¾“å…¥: ").strip()

    if not choice:
        print("âŒ æœªè¾“å…¥ä»»ä½•åˆ—ä¿¡æ¯ï¼")
        return

    selected_columns = []
    choices = [c.strip() for c in choice.split(',')]

    for c in choices:
        if c.isdigit():
            idx = int(c) - 1
            if 0 <= idx < len(columns):
                selected_columns.append(columns[idx])
            else:
                print(f"âŒ åºå· {c} è¶…å‡ºèŒƒå›´ï¼")
                return
        else:
            if c in columns:
                selected_columns.append(c)
            else:
                print(f"âŒ åˆ—å '{c}' ä¸å­˜åœ¨ï¼")
                return

    if not selected_columns:
        print("âŒ æœªé€‰æ‹©ä»»ä½•æœ‰æ•ˆåˆ—ï¼")
        return

    print(f"\nâœ… å·²é€‰æ‹©æ£€æŸ¥ä»¥ä¸‹åˆ—çš„ç©ºç™½: {selected_columns}")

    # 4. è¾“å…¥è¾“å‡ºç›®å½•
    output_dir = input("ğŸ“ è¯·è¾“å…¥ä¿å­˜ç»“æœçš„ç›®å½•è·¯å¾„ï¼ˆç•™ç©ºåˆ™ä¸ºå½“å‰ç›®å½•ï¼‰: ").strip().strip('"\'')
    if not output_dir:
        output_dir = "."
    if not os.path.exists(output_dir):
        confirm = input(f"ğŸ“ ç›®å½•ä¸å­˜åœ¨ï¼Œæ˜¯å¦åˆ›å»º? (y/n): ").strip().lower()
        if confirm != 'y':
            print("âŒ ç”¨æˆ·å–æ¶ˆåˆ›å»ºç›®å½•ã€‚")
            return
        try:
            os.makedirs(output_dir, exist_ok=True)
            print(f"âœ… å·²åˆ›å»ºç›®å½•: {output_dir}")
        except Exception as e:
            print(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥: {e}")
            return

    # 5. è¾“å…¥è¾“å‡ºæ–‡ä»¶å
    output_filename = input("ğŸ“„ è¯·è¾“å…¥è¾“å‡ºæ–‡ä»¶åï¼ˆå¦‚ result.csv æˆ– result.xlsxï¼‰: ").strip().strip('"\'')
    if not output_filename:
        print("âŒ æœªè¾“å…¥æ–‡ä»¶åï¼")
        return

    output_path = os.path.join(output_dir, output_filename)

    # 6. æ‰§è¡Œå¤„ç†
    try:
        clean_spreadsheet(input_path, output_path, selected_columns)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")


def clean_spreadsheet(input_path, output_path, check_columns):
    """
    è¯»å– CSV/XLSX æ–‡ä»¶ï¼Œåˆ é™¤æŒ‡å®šåˆ—ä¸­ä¸ºç©ºçš„è¡Œï¼Œå¹¶ä¿å­˜ç»“æœã€‚
    """
    ext = os.path.splitext(input_path)[1].lower()
    try:
        if ext == '.csv':
            df = pd.read_csv(input_path, encoding='utf-8')
            print(f"âœ… å·²è¯»å– CSV æ–‡ä»¶: {input_path}")
        elif ext in ['.xlsx', '.xls']:
            df = pd.read_excel(input_path)
            print(f"âœ… å·²è¯»å– Excel æ–‡ä»¶: {input_path}")
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")

    # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
    missing_cols = [col for col in check_columns if col not in df.columns]
    if missing_cols:
        raise ValueError(f"ä»¥ä¸‹åˆ—åœ¨æ–‡ä»¶ä¸­æœªæ‰¾åˆ°: {missing_cols}")

    # æ£€æŸ¥ç©ºç™½
    mask = pd.Series([True] * len(df), index=df.index)
    for col in check_columns:
        # åŒæ—¶æ£€æŸ¥ NaN å’Œç©ºå­—ç¬¦ä¸²/çº¯ç©ºæ ¼
        col_not_empty = df[col].notna() & (df[col].astype(str).str.strip() != '')
        mask &= col_not_empty

    cleaned_df = df[mask].reset_index(drop=True)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(output_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # ä¿å­˜
    out_ext = os.path.splitext(output_path)[1].lower()
    try:
        if out_ext == '.csv':
            cleaned_df.to_csv(output_path, index=False, encoding='utf-8-sig')
        elif out_ext in ['.xlsx', '.xls']:
            cleaned_df.to_excel(output_path, index=False)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼: {out_ext}")
        print(f"\nâœ… å¤„ç†å®Œæˆï¼")
        print(f"ğŸ“Š åŸå§‹è¡Œæ•°: {len(df)}")
        print(f"ğŸ§¹ æ¸…ç†åè¡Œæ•°: {len(cleaned_df)}")
        print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        raise Exception(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")


# ========================
# ä¸»ç¨‹åºå…¥å£
# ========================

def main():
    print("ğŸš€ æ¬¢è¿ä½¿ç”¨ xlsxSelector")
    print("æ”¯æŒåŠŸèƒ½ï¼š")
    print("  1) åˆå¹¶å¤šä¸ª CSV/Excel æ–‡ä»¶")
    print("  2) åˆ†å‰²å•ä¸ª CSV/Excel æ–‡ä»¶")
    print("  3) å¯¹ä¸»æ–‡ä»¶è¿›è¡ŒæŸ¥é‡å’Œåˆ é™¤")
    print("  4) æ¸…ç†ç©ºè¡Œ")

    while True:
        print("\n" + "=" * 50)
        choice = get_user_choice(
            "è¯·é€‰æ‹©åŠŸèƒ½: 1) åˆå¹¶  2) åˆ†å‰²  3) æŸ¥é‡  4) æ¸…ç†ç©ºè¡Œ  5) é€€å‡ºï¼ˆé»˜è®¤ 1ï¼‰: ",
            ['1', '2', '3', '4', '5'], '1'
        )

        if choice == '1':
            merge_files()
        elif choice == '2':
            split_excel_or_csv()
        elif choice == '3':
            deduplicate_files()
        elif choice == '4':
            clean_spreadsheet_main()
        elif choice == '5':
            print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
            sys.exit(0)

        # è¯¢é—®æ˜¯å¦ç»§ç»­
        exit_or_continue()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
        sys.exit(0)